{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Installig the packages.\n","!pip install numpy pandas matplotlib imbalanced-learn scikit-learn nltk datasets"],"metadata":{"id":"E5n_RTVLzR9W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load necessary libraries\n","import pandas as pd\n","import re\n","import nltk\n","from datasets import load_dataset\n","from nltk.corpus import stopwords\n","from nltk.corpus import wordnet\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","\n","# Download necessary NLTK datasets\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","nltk.download('averaged_perceptron_tagger')\n","\n","\n","\n","# Loading the dataset to a variable\n","data = load_dataset(\"JulesBelveze/tldr_news\")  ## other dataset was emotion\n","\n","# Downlaod the data in the csv format.\n","for split, dataset in data.items():\n","    dataset.to_csv(f\"my-dataset-{split}.csv\", index=None)\n","\n","\n","# Reload dataset to a variable.\n","data_files = {\n","    \"train\": \"my-dataset-train.csv\",\n","    \"test\": \"my-dataset-test.csv\",\n","}\n"],"metadata":{"id":"ysfKSrfJqpyn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data cleaning\n","To increase the accuracy of our classification model"],"metadata":{"id":"g6mAkqwG0yNK"}},{"cell_type":"code","source":["# Initialize the lemmatizer\n","lemmatizer = WordNetLemmatizer()\n","\n","# Load stopwords and ensure they are in lowercase\n","stop_words = set(word.lower() for word in stopwords.words('english'))\n","\n","def get_wordnet_pos(treebank_tag):\n","    \"\"\"Converts treebank POS tags to WordNet POS tags.\"\"\"\n","    if treebank_tag.startswith('J'):\n","        return wordnet.ADJ\n","    elif treebank_tag.startswith('V'):\n","        return wordnet.VERB\n","    elif treebank_tag.startswith('N'):\n","        return wordnet.NOUN\n","    elif treebank_tag.startswith('R'):\n","        return wordnet.ADV\n","    else:\n","        return None  # Signal that no conversion is possible\n","\n","def clean_and_lemmatize_text(text):\n","    # Keep only ASCII characters\n","    text = text.encode(\"ascii\", \"ignore\").decode()\n","    # Convert text to lowercase and remove URLs\n","    text = re.sub(r'https?://\\S+', '', text.lower())\n","    # Remove non-alphabetic characters and extra spaces\n","    cleaned = re.sub(r'[^a-zA-Z\\s]', '', text)\n","    cleaned = re.sub(r'\\s+', ' ', cleaned).strip()\n","    words = word_tokenize(cleaned)\n","    words_pos = nltk.pos_tag(words)  # Tag words with part-of-speech\n","\n","    processed_words = []\n","    for word, pos_tag in words_pos:\n","        if word not in stop_words and word.strip():\n","            wordnet_pos = get_wordnet_pos(pos_tag)  # Convert to WordNet POS\n","            if wordnet_pos is None:\n","                lemmatized_word = word  # If no conversion was possible, skip lemmatization\n","            else:\n","                lemmatized_word = lemmatizer.lemmatize(word, wordnet_pos)\n","            processed_words.append(lemmatized_word)\n","\n","    return ' '.join(processed_words)\n","\n","\n","def process_dataset(file_path):\n","    \"\"\"Load, clean, and save a dataset.\"\"\"\n","    data = pd.read_csv(file_path)\n","\n","    # Combine 'Headline' and 'Content', then apply cleaning and lemmatization\n","    data['text'] = data['headline'] + ' ' + data['content']\n","    data['processed_text'] = data['text'].apply(clean_and_lemmatize_text)\n","\n","    # Generate a processed file path\n","    processed_file_path = file_path.replace('.csv', '_processed.csv')\n","\n","    # Save the processed dataset\n","    data[['processed_text', 'category']].to_csv(processed_file_path, index=False)\n","\n","    print(f\"Processing completed and saved to {processed_file_path}\")\n","    return processed_file_path\n","\n","# File paths for the datasets\n","train_file_path = '/content/my-dataset-train.csv'  # Adjust as needed\n","test_file_path = '/content/my-dataset-test.csv'  # Adjust as needed\n","\n","# Process both datasets\n","processed_train_path = process_dataset(train_file_path)\n","processed_test_path = process_dataset(test_file_path)"],"metadata":{"id":"RTdRkskznK6n"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Our topics are very similar."],"metadata":{"id":"arxpNiZZG5-c"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","# Load the processed training dataset\n","processed_train_path = '/content/my-dataset-train_processed.csv'\n","data = pd.read_csv(processed_train_path)\n","\n","# Mapping of numerical categories to specified category names\n","category_names = {\n","    0: 'Sponsor',\n","    1: 'Big Tech & Startups',\n","    2: 'Sci & Future',\n","    3: 'Prog, Design & DS',\n","    4: 'Misc'\n","}\n","\n","# Replace numerical category codes with names\n","data['category_name'] = data['category'].map(category_names)\n","\n","# Initialize the CountVectorizer\n","vectorizer = CountVectorizer()\n","X = vectorizer.fit_transform(data['processed_text'])\n","features = vectorizer.get_feature_names_out()\n","\n","# Identify the overall top 20 words across the entire dataset\n","word_counts = np.array(X.sum(axis=0)).flatten()\n","top_20_words_indices = word_counts.argsort()[-20:][::-1]  # Indices of top 20 words\n","top_20_words = np.array(features)[top_20_words_indices]\n","\n","# Function to plot the occurrence of the top 20 words in each category\n","def plot_top_20_words_occurrence(data, top_20_words, category_names):\n","    plt.figure(figsize=(20, 10))\n","\n","    # Create a colormap to have a distinct color for each category\n","    cm = plt.get_cmap('tab20')\n","    colors = [cm(1.*i/len(category_names)) for i in range(len(category_names))]\n","\n","    # Calculate occurrences of top 20 words in each category\n","    for idx, (category_code, category_name) in enumerate(category_names.items()):\n","        category_data = data[data['category'] == category_code]\n","        vectorizer = CountVectorizer(vocabulary=top_20_words)\n","        X_category = vectorizer.fit_transform(category_data['processed_text'])\n","        word_counts = np.array(X_category.sum(axis=0)).flatten()\n","\n","        # Plot\n","        offset = np.arange(len(top_20_words))\n","        plt.bar(offset + idx*0.1, word_counts, width=0.1, label=category_name, color=colors[idx])\n","\n","    plt.xticks(offset + 0.2, top_20_words, rotation=90)\n","    plt.title('Top 20 Words in Each Category')\n","    plt.ylabel('Counts')\n","    plt.xlabel('Words')\n","    plt.legend()\n","    plt.tight_layout()\n","    plt.show()\n","\n","plot_top_20_words_occurrence(data, top_20_words, category_names)\n"],"metadata":{"id":"OojcAiDdNPPQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Imbalanced Data\n","Check if the data is well balanced or not, because this impacts the accuracy of our classifier."],"metadata":{"id":"QfP2aiQwqIay"}},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# Load the processed dataset\n","file_path = '/content/my-dataset-train_processed.csv'  # Adjust to your actual file path\n","data = pd.read_csv(file_path)\n","\n","# Mapping of numerical categories to specified category names\n","category_names = {\n","    0: 'Sponsor',\n","    1: 'Big Tech & Startups',\n","    2: 'Sci & Future',\n","    3: 'Prog, Design & DS',\n","    4: 'Misc'\n","}\n","\n","# Replace numerical category codes with names for plotting\n","data['category_name'] = data['category'].map(category_names)\n","\n","# Check the balance of categories with names\n","category_counts_named = data['category_name'].value_counts()\n","\n","# Plot a histogram with category names\n","plt.figure(figsize=(10, 6))\n","category_counts_named.plot(kind='bar')\n","plt.title('Category Distribution of Training Data')\n","plt.xlabel('Categories')\n","plt.ylabel('Number of Articles')\n","plt.xticks(rotation=45)\n","plt.grid(axis='y', linestyle='--', linewidth=0.7)\n","plt.show()\n","\n"],"metadata":{"id":"7QEfFKKb1GHw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Loading and Preparing the Training Data"],"metadata":{"id":"lon0zcoOzoT4"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# Specify the file paths for the training and test datasets\n","file_path_train = '/content/my-dataset-train_processed.csv'  # Adjust this to your training dataset path\n","file_path_test = '/content/my-dataset-test_processed.csv'  # Adjust this to your test dataset path\n","\n","# Load the training dataset\n","data_train = pd.read_csv(file_path_train)\n","\n","# Load the test dataset\n","data_test = pd.read_csv(file_path_test)\n"],"metadata":{"id":"rOJ0BqZbwoHq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Vectorization\n","Feature Extraction"],"metadata":{"id":"XAK3hLO1z4V2"}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","# Initialize the TfidfVectorizer\n","vectorizer = TfidfVectorizer(max_features=5000)\n","\n","# Fit the vectorizer on the training data and transform the training data to document-term matrix\n","X_train = vectorizer.fit_transform(data_train['processed_text']).toarray()\n","\n","# Transform the test data to document-term matrix using the same vectorizer\n","X_test = vectorizer.transform(data_test['processed_text']).toarray()\n","\n","# Extract the category labels for the training and test data\n","y_train = data_train['category']\n","y_test = data_test['category']\n"],"metadata":{"id":"_hP0gyTy23yQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Balancing Data with SMOTE\n","We are oversampling the minority class in the training data."],"metadata":{"id":"TCXY-ROn3Hpd"}},{"cell_type":"code","source":["from imblearn.over_sampling import SMOTE\n","\n","smote = SMOTE(random_state=42)\n","X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n","\n","\n","# Visualize the new class distribution\n","new_class_distribution = pd.Series(y_train_smote).value_counts()\n","\n","plt.figure(figsize=(10, 6))\n","new_class_distribution.plot(kind='bar')\n","plt.title('Class Distribution After SMOTE')\n","plt.xlabel('Category')\n","plt.ylabel('Number of Articles')\n","plt.xticks(rotation=45)\n","plt.grid(axis='y', linestyle='--', linewidth=0.7)\n","plt.show()"],"metadata":{"id":"ij1kQWYY3at9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training the Naive Bayes Classifer\n","Train a Multinomial Naive Bayes classifier, which is suitable for classification with discrete features (like word counts or TF-IDF) for text classification tasks."],"metadata":{"id":"B4CWeQ5U3iE6"}},{"cell_type":"code","source":["from sklearn.naive_bayes import MultinomialNB\n","\n","classifier = MultinomialNB()\n","classifier.fit(X_train_smote, y_train_smote)\n"],"metadata":{"id":"25EiS6pX3hte"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Evaluate the classifier on Training Data."],"metadata":{"id":"U5itqkBRe03I"}},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","\n","# Predicting the categories for the training dataset\n","y_train_pred = classifier.predict(X_train_smote)\n","\n","# Generating the classification report for the training data\n","report = classification_report(y_train_smote, y_train_pred, target_names=category_names.values())\n","print(\"Classification Report of Training Data:\\n\", report)\n"],"metadata":{"id":"jd2Zm1sXe0RZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Saving the classifer and Vectorizer"],"metadata":{"id":"GognN-eU35qk"}},{"cell_type":"code","source":["import joblib\n","\n","# Save the classifier\n","joblib.dump(classifier, '/content/naive_bayes_classifier.pkl')\n","\n","# Save the vectorizer\n","joblib.dump(vectorizer, '/content/tfidf_vectorizer.pkl')\n"],"metadata":{"id":"J-27dz3v3zIa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Using the classifer on Test Data"],"metadata":{"id":"Y9iRqraq4FxI"}},{"cell_type":"code","source":["# Load the classifier and vectorizer\n","classifier = joblib.load('/content/naive_bayes_classifier.pkl')\n","vectorizer = joblib.load('/content/tfidf_vectorizer.pkl')\n","\n","# Load your test data\n","file_path_test = '/content/my-dataset-test_processed.csv'  # Adjust this to your test dataset path\n","data_test = pd.read_csv(file_path_test)\n","\n","# Vectorize the test data\n","X_test = vectorizer.transform(data_test['processed_text']).toarray()\n","\n","# Predict\n","predictions = classifier.predict(X_test)\n","\n","# You can then compare these predictions with the actual labels to evaluate the classifier\n"],"metadata":{"id":"2s2uvPDo4LS_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Evalute your test data."],"metadata":{"id":"nTzN4mH-rdZW"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import joblib\n","\n","# Step 1: Load the saved classifier and vectorizer\n","classifier = joblib.load('/content/naive_bayes_classifier.pkl')\n","vectorizer = joblib.load('/content/tfidf_vectorizer.pkl')\n","\n","# Step 2: Prepare the test data\n","# Assuming 'processed_test_path' is the path to your processed test dataset\n","data_test = pd.read_csv(processed_test_path)\n","X_test = vectorizer.transform(data_test['processed_text']).toarray()  # Transform the test data\n","y_test = data_test['category']  # True labels of the test data\n","\n","# Step 3: Predict on the test data\n","y_pred = classifier.predict(X_test)\n","\n","# Step 4: Evaluate the performance\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Accuracy: {accuracy * 100:.2f}%\")\n","\n","# Detailed classification report\n","print(\"\\nClassification Report of Test Data:\\n\")\n","print(classification_report(y_test, y_pred, target_names=category_names.values()))\n"],"metadata":{"id":"Fb5GypFtrggC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Confusion Matrix because our data was imbalanced.\n","## Interpreting the Matrix\n","1.   Each cell [i, j] in the matrix shows the number of instances of class i (actual) that were predicted as class j (predicted).\n","2.   Main Diagonal: The cells along the main diagonal from the top left to the bottom right ([i, i] for all i) show the number of correct predictions for each class. High numbers along this diagonal indicate good performance.\n","3.   Off-Diagonal: The off-diagonal cells show misclassifications. For cell [i, j], the number indicates instances of class i being misclassified as class j. High numbers in these cells indicate areas where the model is confusing classes."],"metadata":{"id":"etkHjZ0EwA-A"}},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","\n","# Assuming y_test contains the true labels and y_pred contains the predicted labels from your classifier\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","\n","# Plotting the confusion matrix\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n","            xticklabels=category_names.values(), yticklabels=category_names.values())\n","plt.title('Confusion Matrix')\n","plt.xlabel('Predicted Labels')\n","plt.ylabel('True Labels')\n","plt.show()\n"],"metadata":{"id":"FRUHzAYburYs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## tokenizing our csv file and than applying search engine"],"metadata":{"id":"-JO4bMtwaNRe"}},{"cell_type":"code","source":["!pip install rank-bm25\n","\n","import pandas as pd\n","from rank_bm25 import BM25Okapi\n","\n","# Load the original and processed training datasets\n","train_original_path = '/content/my-dataset-train.csv'\n","train_processed_path = '/content/my-dataset-train_processed.csv'\n","data_train_original = pd.read_csv(train_original_path)\n","data_train_processed = pd.read_csv(train_processed_path)\n","\n","# Load the original and processed test datasets\n","test_original_path = '/content/my-dataset-test.csv'\n","test_processed_path = '/content/my-dataset-test_processed.csv'\n","data_test_original = pd.read_csv(test_original_path)\n","data_test_processed = pd.read_csv(test_processed_path)\n","\n","# Tokenize the processed text from training and test datasets\n","tokenized_corpus_train = [text.split() for text in data_train_processed['processed_text']]\n","\n","# Initialize BM25 with the tokenized training corpus\n","bm25 = BM25Okapi(tokenized_corpus_train)\n","\n","def bm25_search(query, top_n=4):\n","    # Tokenize the query\n","    query_tokens = query.lower().split()\n","\n","    # Get scores for each document in the training corpus\n","    train_scores = bm25.get_scores(query_tokens)\n","\n","    # Get the top scoring documents indices from the training data\n","    top_train_indices = train_scores.argsort()[::-1][:top_n]\n","\n","    # Extract top documents from both original training dataframes\n","    top_docs_train_original = data_train_original.iloc[top_train_indices]\n","\n","    # Now score the test data separately\n","    tokenized_corpus_test = [text.split() for text in data_test_processed['processed_text']]\n","    bm25_test = BM25Okapi(tokenized_corpus_test)\n","    test_scores = bm25_test.get_scores(query_tokens)\n","    top_test_indices = test_scores.argsort()[::-1][:top_n]\n","    top_docs_test_original = data_test_original.iloc[top_test_indices]\n","\n","    return top_docs_train_original, top_docs_test_original, train_scores[top_train_indices], test_scores[top_test_indices]\n","\n","# Example usage\n","query = \"web animation performance fundamentals\"\n","top_docs_train_original, top_docs_test_original, top_train_scores, top_test_scores = bm25_search(query)\n","print(\"Top Training Documents Based on BM25 Scores:\")\n","print(top_docs_train_original)\n","print(\"\\nBM25 Scores for Top Training Documents:\")\n","print(top_train_scores)\n","\n","print(\"\\nTop Test Documents Based on BM25 Scores:\")\n","print(top_docs_test_original)\n","print(\"\\nBM25 Scores for Top Test Documents:\")\n","print(top_test_scores)\n"],"metadata":{"id":"ufvhENaIFTeu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Testing\n","Testing the effectiveness of a BM25 model in a realistic setting typically involves assessing how well the model retrieves documents that are relevant to the queries posed to it. This involves comparing the model's outputs against a set of known, relevant documents for each query, often referred to as a \"ground truth.\" This relevance data (ground truth) needs to be accurate for true evaluation of the BM25 model and for which we need to create a \"Query Dictionary\", which would lead to step backward when using BM25 from the libirary."],"metadata":{"id":"OH0Gt6IVoiC7"}}]}